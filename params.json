{"name":"Moneyball in the NBA","tagline":"","body":"### Welcome to my Data Science Project on the Predictive Accuracy of Basketball Statistics\r\n\r\nThe hypothesis I looked to explore in the project is: Can wins in the NBA be predicted by statistics other than points scored or points allowed?  This project is an extension of the ideology made famous by the movie Moneyball in which the Oakland Athletics sought different skills in players other than the expensive, most sought after skills (hits, homeruns...) and were able to make the playoffs due to the predictive accuracy of these statistics.  This ideology that there may be many other statistics other than the obvious that predict wins is what I looked to explore in the NBA.\r\n\r\n\r\n### Setting Explanatory Features\r\nMy explanatory features stem from every basic statistic available from the last 35 years in the NBA.  One of the first things to check is if any correlation between the features exist, shown here by a correlation matrix...\r\n\r\n![](https://github.com/macohen2/MattsProject/blob/master/images/sample.png)\r\n\r\n### Predicting a Successful Season\r\nRather than predict the exact number of wins a team will achieve based upon team statistics, I decided to predict what most coaches and player care about, and that is whether or not a team will make the playoffs (generally speaking a team is considered to be a good team if they make the playoffs).  To do this I used a Random Forests classification method in order to predict a created categorical feature marking whether or not a team made the playoffs.\r\n\r\n### Grid Search for Best Parameters, ROC score and True Positive/Negative Rate\r\nA grid search is conducted to tune the model to use its best parameters.  Using all the explanatory features, the predictive accuracy for a playoff team measured by ROC/AUC is 0.92 and True Positive/Negative accuracy rate of 91%.\r\n\r\n![](https://github.com/macohen2/MattsProject/blob/master/images/Grid%20Search%201.png)\r\n![](https://github.com/macohen2/MattsProject/blob/master/images/P:N%201.png)\r\n\r\n### Finding Feature Importances\r\nHypothesis #2: Is there a select number of features (3 or 4) that can predict wins while maintaining good accuracy?  Are there certain aspect of the game players/coaches can focus on other than scoring points that con predict whether or not a team wins or not?  In order to do that, I first take a look at a list of my feature importances.\r\n\r\n![](https://github.com/macohen2/MattsProject/blob/master/images/Feature%20Importances.png)\r\n\r\n### Recursive Feature Elimination and Final Accuracy of Selected Features\r\nEliminating features such that only the most predictive remain.\r\nUsing just these 3 features (Defensive Rebounds, Assists Allowed, Field Goal Percentage), this model can predict whether or not a team will make the playoffs 84% of the time!  In basketball terms, if a team focusses on dominating defensive rebounds, forcing the other team to score on isolation plays and not team basketball, and focus on taking high percentage shots, without even considering points, this team has a very good chance of making the playoffs and competing for a championship.\r\n\r\n![](https://github.com/macohen2/MattsProject/blob/master/images/P:N%202.png)\r\n\r\nYou can view my code and the full project at this link:\r\nhttp://nbviewer.ipython.org/github/macohen2/MattsProject/blob/master/A%20Different%20Moneyball.ipynb","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}